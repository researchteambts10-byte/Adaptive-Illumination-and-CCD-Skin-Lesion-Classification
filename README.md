# Adaptive Illumination Normalization and Color-Contrast-Depth Segmentation Based Skin Lesion Classification Model Using Deep CNN (ALN-C2D-DCNN)

## ðŸ“˜ Description
This repository presents the **ALN-C2D-DCNN** model â€” a robust deep learning framework for automated **skin lesion classification**.  
The model integrates **Adaptive Illumination Normalization (ALN)** and **Color-Contrast-Depth (C2D) Segmentation**, enhancing image contrast and extracting critical lesion features based on **color, contrast, and depth**.  
Using a custom **Deep Convolutional Neural Network (DCNN)**, this framework achieves up to **99% classification accuracy**, outperforming existing deep models in accuracy and efficiency.


## ðŸ§© Dataset Information
- **Dataset Used:** [HAM10000](https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000), ISIC 2016-2020 challenge datasets.
- **Samples:** 10,015 dermatoscopic images.
- **Classes:** Melanoma, Nevus, Basal Cell Carcinoma, Dermatofibroma, Benign Keratosis, Actinic Keratosis, and others.
- **Metadata:** Includes patient age, gender, lesion location, and diagnostic confirmation.

---

## ðŸ’» Code Information
### Project Structure
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ test/
â”‚   â””â”€â”€ metadata.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ aln_c2d_dcnn.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ segmentation.py
â”‚   â””â”€â”€ evaluation.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train.py
â”œâ”€â”€ test.py
â””â”€â”€ README.md
```





## Core Modules
- `preprocessing.py` â€“ Adaptive Illumination Normalization (CIF computation)
- `segmentation.py` â€“ C2D Segmentation and ROI extraction
- `train.py` â€“ CNN model training with transfer learning
- `test.py` â€“ Evaluation and classification metrics

---

## ðŸš€ Usage Instructions
1. **Clone the repository**
   ```bash
   git clone https://github.com/researchteambts10-byte/Adaptive-Illumination-and-CCD-Skin-Lesion-Classification.git
   cd Adaptive-Illumination-and-CCD-Skin-Lesion-Classification

   
2. **Install dependencies**
    pip install -r requirements.txt

3. **Prepare dataset**
    - Download HAM10000 or ISIC dataset.
    - Place the images inside data/train/ and data/test/.
  
4. Train the model
    python train.py

5. Test and evaluate
    python test.py

6. Expected Output
    - Classification Accuracy: ~99%
    - False Classification Ratio: <3%
    - Reduced Time Complexity: ~29.7%

## âš™ï¸ Requirements

| Component          | Details                                                         |
| ------------------ | --------------------------------------------------------------- |
| **CPU**            | Intel Core i7-12700K @ 3.60GHz                                  |
| **GPU**            | NVIDIA GeForce RTX 3080 (10GB GDDR6X)                           |
| **RAM**            | 32 GB DDR4                                                      |
| **OS**             | Ubuntu 22.04 LTS                                                |
| **Frameworks**     | TensorFlow 2.11.0 / PyTorch 1.13.1                              |
| **CUDA Version**   | 11.7                                                            |
| **Python Version** | 3.9.13                                                          |
| **Libraries**      | NumPy, TensorFlow, PyTorch, Keras, OpenCV, Pandas, scikit-learn |

---

## ðŸ§  Methodology
The ALN-C2D-DCNN model operates in four major phases:

1. **Adaptive Illumination Normalization (ALN):**
   - Normalizes illumination across lesion images using neighborhood pixel intensity and red-channel based Color Intensity Factor (CIF).
   - Enhances local contrast for better lesion visibility.

2. **C2D Segmentation:**
   - Segments lesion regions using color, contrast, and depth similarity (C2DS).
   - Employs region growing to localize the Region of Interest (ROI).

3. **Transfer Learning and Data Augmentation:**
   - Applies shearing, rotation (90Â°, 180Â°, 270Â°), and scaling to expand dataset variability.

4. **CNN Training and Classification:**
   - Custom CNN architecture with convolution, pooling, and fully connected layers.
   - Extracted C2D features are trained and classified based on C2D Weights (C2DW).

---

## ðŸ“„ License

This project is distributed under the MIT License.



